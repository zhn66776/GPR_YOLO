{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179d9f3b-a551-426a-a141-13f3135ee27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Input and output folders\n",
    "input_folder = r\"C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\Category 1 - grey scale\"\n",
    "output_folder = r\"C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\Category 1 augmented output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166af001-ed8b-473b-8b0f-ce37fadf749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target resolutions\n",
    "original_size = (500, 350)\n",
    "horizontal_stretch = (1400, 500)  # width x height\n",
    "vertical_stretch = (500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f6a701-753d-4538-bbb5-515883edf31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Augmentation complete! Images saved in 'category1_output'\n"
     ]
    }
   ],
   "source": [
    "# Go through each image\n",
    "for idx, filename in enumerate(sorted(os.listdir(input_folder))):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        path = os.path.join(input_folder, filename)\n",
    "        img = Image.open(path).convert(\"L\")  # Grayscale\n",
    "\n",
    "        # Resize to original target size\n",
    "        img_orig = img.resize(original_size)\n",
    "\n",
    "        # 1. Save original resized\n",
    "        img_orig.save(os.path.join(output_folder, f\"{idx}_orig.png\"))\n",
    "\n",
    "        # 2. Horizontal stretch\n",
    "        img_hs = img.resize(horizontal_stretch)\n",
    "        img_hs.save(os.path.join(output_folder, f\"{idx}_horz_stretch.png\"))\n",
    "\n",
    "        # 3. Vertical stretch\n",
    "        img_vs = img.resize(vertical_stretch)\n",
    "        img_vs.save(os.path.join(output_folder, f\"{idx}_vert_stretch.png\"))\n",
    "\n",
    "        # 4. Flips\n",
    "        img_orig_flipped = ImageOps.mirror(img_orig)\n",
    "        img_orig_flipped.save(os.path.join(output_folder, f\"{idx}_orig_flip.png\"))\n",
    "\n",
    "        img_hs_flipped = ImageOps.mirror(img_hs)\n",
    "        img_hs_flipped.save(os.path.join(output_folder, f\"{idx}_horz_stretch_flip.png\"))\n",
    "\n",
    "        img_vs_flipped = ImageOps.mirror(img_vs)\n",
    "        img_vs_flipped.save(os.path.join(output_folder, f\"{idx}_vert_stretch_flip.png\"))\n",
    "\n",
    "print(\"✅ Augmentation complete! Images saved in 'category1_output'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e569a024-eb5f-45c2-a5ff-209d1cf4bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output folders\n",
    "input_folder = r\"C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\Category 2 - blue tinted\"\n",
    "output_folder = r\"C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\Category 2 augmented output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4ee76d-2720-43c6-9e7e-9031de3de7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092c8616-f4dd-4a00-b2c9-47b180dc1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Category 2 images cropped, sharpened, and saved in 'category2_output'\n"
     ]
    }
   ],
   "source": [
    "# Crop fraction (keep 80% from center)\n",
    "crop_fraction = 0.8\n",
    "\n",
    "for idx, filename in enumerate(sorted(os.listdir(input_folder))):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        img_gray = img.convert(\"L\")\n",
    "\n",
    "        # Get original size\n",
    "        width, height = img_gray.size\n",
    "\n",
    "        # Crop central 80%\n",
    "        new_width = int(width * crop_fraction)\n",
    "        new_height = int(height * crop_fraction)\n",
    "        left = (width - new_width) // 2\n",
    "        top = (height - new_height) // 2\n",
    "        right = left + new_width\n",
    "        bottom = top + new_height\n",
    "        img_cropped = img_gray.crop((left, top, right, bottom))\n",
    "\n",
    "        # Apply sharpening\n",
    "        img_sharp = img_cropped.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "        # Optionally enhance contrast\n",
    "        enhancer = ImageEnhance.Contrast(img_sharp)\n",
    "        img_final = enhancer.enhance(1.2)  # 1.0 = original, >1 = more contrast\n",
    "\n",
    "        # Save the processed image\n",
    "        output_path = os.path.join(output_folder, f\"{idx}_cropped_clear.png\")\n",
    "        img_final.save(output_path)\n",
    "\n",
    "print(\"✅ Category 2 images cropped, sharpened, and saved in 'category2_output'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef5d88c-4b61-4384-b976-32d5e994379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imgaug in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (0.4.0)\n",
      "Requirement already satisfied: Pillow in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from imgaug) (11.0.0)\n",
      "Requirement already satisfied: Shapely in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from imgaug) (2.0.6)\n",
      "Requirement already satisfied: imageio in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from imgaug) (2.37.0)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from imgaug) (0.24.0)\n",
      "Requirement already satisfied: opencv-python in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from imgaug) (4.12.0.88)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from imgaug) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from imgaug) (3.9.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from imgaug) (2.0.2)\n",
      "Requirement already satisfied: scipy in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from imgaug) (1.13.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from scikit-image>=0.14.2->imgaug) (3.2.1)\n",
      "Requirement already satisfied: packaging>=21 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from scikit-image>=0.14.2->imgaug) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from scikit-image>=0.14.2->imgaug) (0.4)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from scikit-image>=0.14.2->imgaug) (2024.8.30)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug) (6.4.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug) (3.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug) (4.55.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from matplotlib->imgaug) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib->imgaug) (3.20.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abfb2c50-7f7e-46b8-8018-57ac5a24131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (2.0.8)\n",
      "Requirement already satisfied: PyYAML in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albumentations) (1.13.1)\n",
      "Requirement already satisfied: eval-type-backport in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albumentations) (0.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albumentations) (4.12.2)\n",
      "Requirement already satisfied: albucore==0.0.24 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albumentations) (2.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albumentations) (2.11.7)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albucore==0.0.24->albumentations) (3.12.6)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from albucore==0.0.24->albumentations) (6.5.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/haonanzhang/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install albumentations --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0a94f7-69ca-4702-96ea-6bbdc5c2a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ada4775-c12e-4dc0-b776-587a64c2cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prita\\AppData\\Local\\Temp\\ipykernel_22956\\3492812620.py:30: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 25.0), p=0.5),  # Low Gaussian noise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Augmented 3096 images. Saved 2786 to train and 310 to val.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "\n",
    "# Set folders\n",
    "input_folder = r\"C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\combined firt step augmented images\"\n",
    "train_folder = r\"C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\output train data\"\n",
    "val_folder = r\"C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\output validation data\"\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(val_folder, exist_ok=True)\n",
    "\n",
    "# Load all 502 grayscale images\n",
    "images = []\n",
    "image_names = []\n",
    "\n",
    "for fname in sorted(os.listdir(input_folder)):\n",
    "    if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(input_folder, fname)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            image_names.append(fname)\n",
    "\n",
    "# Define Albumentations augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),                     # 50% chance to flip\n",
    "    A.RandomBrightnessContrast(p=0.8, brightness_limit=0.2, contrast_limit=0.2),\n",
    "    A.GaussNoise(var_limit=(10.0, 25.0), p=0.5),  # Low Gaussian noise\n",
    "    A.Resize(256, 256)\n",
    "])\n",
    "\n",
    "# Augment each image 6 times\n",
    "augmented_images = []\n",
    "augmented_names = []\n",
    "\n",
    "for idx, img in enumerate(images):\n",
    "    for aug_idx in range(6):\n",
    "        augmented = transform(image=img)\n",
    "        aug_img = augmented[\"image\"]\n",
    "        augmented_images.append(aug_img)\n",
    "        augmented_names.append(f\"{idx}_{aug_idx}.png\")\n",
    "\n",
    "# Split into train and validation sets (90% : 10%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    augmented_images, augmented_names, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Save to disk\n",
    "for img, name in zip(X_train, y_train):\n",
    "    cv2.imwrite(os.path.join(train_folder, name), img)\n",
    "\n",
    "for img, name in zip(X_val, y_val):\n",
    "    cv2.imwrite(os.path.join(val_folder, name), img)\n",
    "\n",
    "print(f\"✅ Augmented {len(augmented_images)} images. Saved {len(X_train)} to train and {len(X_val)} to val.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2696634a-ee78-4684-bc39-47c3743c4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "image_dir = r'yolo_data/images/validation'\n",
    "label_dir = r'yolo_data/labels/validation'\n",
    "os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "def generate_yolo_labels(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    height, width = img.shape\n",
    "\n",
    "    # Threshold to extract bright regions (hyperbolas)\n",
    "    _, thresh = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w * h < 300:  # Skip small noise\n",
    "            continue\n",
    "\n",
    "        # Normalize to YOLO format\n",
    "        x_center = (x + w / 2) / width\n",
    "        y_center = (y + h / 2) / height\n",
    "        norm_w = w / width\n",
    "        norm_h = h / height\n",
    "\n",
    "        boxes.append(f\"0 {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\")\n",
    "\n",
    "    return boxes\n",
    "\n",
    "# Process all images\n",
    "for img_file in os.listdir(image_dir):\n",
    "    if img_file.lower().endswith(('.jpg', '.png')):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        label_path = os.path.join(label_dir, img_file.rsplit('.', 1)[0] + '.txt')\n",
    "        labels = generate_yolo_labels(img_path)\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            for line in labels:\n",
    "                f.write(line + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e9b9aa-d298-4f85-a024-e8d6022e7fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bounding box visualizations saved to: vis_val\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# === Set Paths ===\n",
    "image_dir = r\"yolo_data/images/validation\"\n",
    "label_dir = r\"yolo_data/labels/validation\"\n",
    "\n",
    "# Output folder to save visualizations\n",
    "output_dir = r\"vis_val\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === Loop through images and draw bounding boxes ===\n",
    "for img_file in os.listdir(image_dir):\n",
    "    if not img_file.lower().endswith(('.jpg', '.png')):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(image_dir, img_file)\n",
    "    label_path = os.path.join(label_dir, os.path.splitext(img_file)[0] + \".txt\")\n",
    "\n",
    "    # Load image\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Read labels\n",
    "    if os.path.exists(label_path):\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                class_id, x_center, y_center, box_w, box_h = map(float, parts)\n",
    "\n",
    "                # Convert from YOLO format to pixel coordinates\n",
    "                x1 = int((x_center - box_w / 2) * w)\n",
    "                y1 = int((y_center - box_h / 2) * h)\n",
    "                x2 = int((x_center + box_w / 2) * w)\n",
    "                y2 = int((y_center + box_h / 2) * h)\n",
    "\n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(img, f\"hyperbola\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Save visualization\n",
    "    out_path = os.path.join(output_dir, img_file)\n",
    "    cv2.imwrite(out_path, img)\n",
    "\n",
    "print(f\"✅ Bounding box visualizations saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240fb76d-e9af-485c-8886-d98f48a9a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "image_dir = r'C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\output validation data'\n",
    "label_dir = r'C:\\Users\\prita\\OneDrive\\Desktop\\gpr project2\\output validation data labels'\n",
    "os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "def generate_yolo_labels(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    height, width = img.shape\n",
    "\n",
    "    # Threshold to extract bright regions (hyperbolas)\n",
    "    _, thresh = cv2.threshold(img, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w * h < 300:  # Skip small noise\n",
    "            continue\n",
    "\n",
    "        # Normalize to YOLO format\n",
    "        x_center = (x + w / 2) / width\n",
    "        y_center = (y + h / 2) / height\n",
    "        norm_w = w / width\n",
    "        norm_h = h / height\n",
    "\n",
    "        boxes.append(f\"0 {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\")\n",
    "\n",
    "    return boxes\n",
    "\n",
    "# Process all images\n",
    "for img_file in os.listdir(image_dir):\n",
    "    if img_file.lower().endswith(('.jpg', '.png')):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        label_path = os.path.join(label_dir, img_file.rsplit('.', 1)[0] + '.txt')\n",
    "        labels = generate_yolo_labels(img_path)\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            for line in labels:\n",
    "                f.write(line + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75edb6",
   "metadata": {},
   "source": [
    "## split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ffa3b5-9649-4b31-a334-5591cf1de688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! 已复制 576 个文件到 second_half_training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 原始文件夹\n",
    "src_dir = \"yolo_data/images/training\"\n",
    "# 输出文件夹\n",
    "dst_dir = \"second_half_training\"\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# 获取所有文件（排序确保顺序一致）\n",
    "files = sorted(os.listdir(src_dir))\n",
    "n = len(files)\n",
    "half_n = n // 2   # 前50%\n",
    "\n",
    "# 复制前一半文件\n",
    "for f in files[half_n:]:\n",
    "    src_path = os.path.join(src_dir, f)\n",
    "    dst_path = os.path.join(dst_dir, f)\n",
    "    shutil.copy2(src_path, dst_path)   # copy2 会保留时间戳\n",
    "\n",
    "print(f\"✅ Done! 已复制 {half_n} 个文件到 {dst_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
